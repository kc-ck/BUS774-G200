{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Python for Data Analysis \n",
    "## Part 2: Working with Data\n",
    "### C Kaligotla | BUS 774 G200 \n",
    "### 04 Feb 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Introduction to Data Frames and Pandas\n",
    "2. Loading and Importing Data\n",
    "3. Selecting and Filtering Data\n",
    "4. Filtering Data\n",
    "5. Recoding Data\n",
    "6. Dealing with misisng values\n",
    "7. Grouping \n",
    "8. Creating New Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chapter 1: Python Libraries - Pandas, and DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Python library (or package) contains things (objects, code) that is not part of the core Python language but is nonetheless useful to some community of users. \n",
    "\n",
    "Libraries save us from re-inventing the wheel: Once someone has created a library and made it available for download, we can use the contents of the library in our own Python programs.\n",
    "\n",
    "For example, to use the pandas.DataFrame object in our programs, we must first import the Pandas library into our environment.\n",
    "\n",
    "A nice guide to pandas: https://pandas.pydata.org/pandas-docs/stable/user_guide/10min.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading pandas library\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The pd here is simply shortform or an alias for pandas.\n",
    "- To call on the library, the structure is <library/alias>.function(input)\n",
    "- With alias pd for pandas, we can simply type pd.function(input)\n",
    "    - e.g., pd.read_csv(input file) calls the read_csv function from pandas library into a directed input file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrames are special object structures in the Pandas library\n",
    "- They are multidimensional arrays, just like excel!\n",
    "- different columns can have different data types (strings, numbers, boolean...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating DataFrame objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's create a DataFrame object called df\n",
    "# notice the structure: \n",
    "    #First the Column name, a :, and then individual rows for that column within [ ]\n",
    "        # just like in a dictionary!\n",
    "    # a comma to separate columns, and rinse and repeat \n",
    "\n",
    "df = pd.DataFrame({'Artist':['Billie Holiday','Jimi Hendrix', 'Miles Davis', 'SIA'],\n",
    "              'Genre': ['Jazz', 'Rock', 'Jazz', 'Pop'],\n",
    "              'Listeners': [1300000, 2700000, 1500000, 2000000],\n",
    "              'Plays': [27000000, 70000000, 48000000, 74000000]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#To view the dataframe, just use print or type the name of the dataframe object\n",
    "print(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Data using Pandas DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - use pd.read_csv(file) to import a csv file\n",
    "    - use pd.read_excel(file) to import an excel file\n",
    "    - For other file types, look up the command!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <B>Hint 1:</B>\n",
    "    Pointing to a file on your computer is always tricky when you don't have a pop-up file system chooser like you do in most Windows applications. Some basic hints:\n",
    "<OL>\n",
    "    <LI>If practical, put the data file in the same folder as your Jupyter notebook.  In the example above, I created a subfolder called \"Data\" and put the bank data there.  This makes it easier for you to remember (and type) the path to the data file.</LI>\n",
    "    <LI>If your data must reside somewhere else on your computer or network: Be very careful when typing.  Cut and paste the path from Windows Explorer if required.</LI>\n",
    "    <LI>Beware the slashes/backslashes. Unix-like operating systems seperate directory names with a slash \"/\" whereas Microsoft Windows uses a backslash \"\\\". In general, Python seperates folders with forward slashes.  The backward slash is used in Python as the 'escape' character.  If you cut and paste from Windows Explorer, you must either change all the backslashes to slashes or add the \"r\" prefix to your pathname to indicate a \"raw\" string of text (Python will ingore the special meaning of backslashes).  So the following should work for a more complex file location:\n",
    "    <OL>\n",
    "        <LI><code>pd.read_csv('C:/Users/CK/Data/Bank.csv\")</code> &mdash; all forward slashes</LI>\n",
    "        <LI><code>pd.read_csv(r'C:\\Users\\CK\\Data/Bank.csv\")</code> &mdash; mixture of slashes and backslashes with the \"r\" prefix</LI>\n",
    "     </OL>\n",
    "\n",
    "</OL>\n",
    "<B>Hint 2: Use Dropbox / Google Drive / etc.. </B>\n",
    " <LI>Save the location as a separate string object (like url)</LI>\n",
    " <LI>Ensure there is dl=1 at the end of the string</LI>\n",
    "     <LI> point pandas input to the url object</LI>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url =\"https://www.dropbox.com/s/dmhumwapmrqe4j0/Bank.csv?dl=1\" \n",
    "# You can load data directly from a dropbox link - just make sure dl=1 in the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank = pd.read_csv(url) \n",
    "# assign data to an object (dataframe) called bank. You can name this whatever you like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank # to view the dataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Structure to call functions: <dataFrame_Object>.functions\n",
    "    ().shape gives # of rows and colms\n",
    "    ().info() gives the data type and null counts for ALL columns\n",
    "    ().describe() generates summary statistics for the numerical columns\n",
    "    \n",
    "Notice the difference between a property like shape with no parentheses while a method like describe() has parentheses!\n",
    "Parantheses for functions implies the ability to pass arguments to these functions.\n",
    "\n",
    "Hint: Press the Shift-Tab key while within the parantheses of a Python method for a list of the possible arguments. Hit Shift-Tab twice to get more detailed help. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n",
    "# notice all columns are here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe() \n",
    "# notice it only summarizes numerical columns!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now repeat the same for the bank dataFrame!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting strings to categories\n",
    "\n",
    "It is useful to recognize strings in Data to refer to classifiers or Categories\n",
    "\n",
    "Pandas permits you to recognize character data to relate to categorical data - called _category_.  \n",
    "\n",
    "The process for replacing the two (string) \"Object\" columns with categories is using .astype('category') function.\n",
    "\n",
    "The key is understanding how to reference columns in Python.  \n",
    "Two possibilities:\n",
    "    - square bracket notation: `bank['Gender']`\n",
    "    - dot notation: `bank.Gender`\n",
    "\n",
    "Of these two, square bracket notation is slightly more flexible because it permits column names with spaces, e.g., `dataframe['column name']`.  \n",
    "The dot notation of this would fail because Python has no way of knowing what the space after \"column\" means: `dataframe.column name`.\n",
    "\n",
    "Once we know how to reference a column (or a \"Series\" in Pandas-speak), we can run the type conversion method and specify \"category\" as the output data type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example: let's convert the gender column in the bank data as a categorical variable\n",
    "bank['Gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank['Gender'].astype('category') # While it looks the same - see the last line!\n",
    "#python recognizes 2 categories!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the command above just lists the converted values;\n",
    "We did not do anything to save it into the \"bank\" data frame. \n",
    "To replace the existing column in the data frame, we use the assignment operator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank['Gender'] = bank['Gender'].astype('category')\n",
    "#This code no rewrites the Gender column as a category type!\n",
    "bank.info() # look at the Categorty column! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now repeat the same for PCJob Column\n",
    "bank['PCJob']\n",
    "# Write down the command to convert this into a category!\n",
    "bank['PCJob'] = ......"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Note that you can get summary statistics for categorical data by using .describe() function \n",
    "    -- just put an (include='category') within the describe function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank.describe(include='category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chapter 2: Data Operations: Filtering and Recoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selection, Filtering, and Subsetting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can select any column using its label:\n",
    "df['Artist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can save this as a separate object or list!\n",
    "artist_list = df['Artist']\n",
    "artist_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can select one or multiple rows using their numbers (inclusive of both bounding row numbers):\n",
    "# <dataframe>.loc[rows] does this\n",
    "df.loc[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remember - everything in python begins with a 0\n",
    "# Call row 0 in the df dataframe!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can select any slice of the table using a both column label and row numbers using loc:\n",
    "# <dataframe>.loc[rows,['column(s)']] does this\n",
    "df.loc[1:3,['Artist']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try this on the bank dataframe!\n",
    "# let's save all employee and Salary data for the first 10 rows!\n",
    "bank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering, and Subsetting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it gets more interesting. We can easily filter rows using the values of a specific row. \n",
    "For example, here are our jazz musicians:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Genre'] == \"Jazz\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank['Gender'] == 'Female'\n",
    "# this expression only checks the conditional across all rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this on the other hand subsets or filters the dataframe based on the boolean check!\n",
    "bank[bank['Gender'] == \"Female\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's filter and save as a different dataframe - male and female employees in the bank!\n",
    "bank_1 = bank[bank['Gender']==\"Male\"]\n",
    "bank_2 = bank[bank['Gender']!=\"Male\"] # or == \"Female\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_1.describe(include='category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_2.describe(include='category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now back to the artist data set\n",
    "# Here are the artists who have more than 1,800,000 listeners:\n",
    "df[df['Listeners'] > 1800000 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISE \n",
    "## let's filter bank dataset by employees with above median salary!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grouping Function\n",
    "If you want to group multiple variables in a dataframe based on a categorical column, and run a function, this is the structure:\n",
    "<dataframe>.groupby('col').function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## what does this function do?\n",
    "df.groupby('Genre').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise\n",
    "#. Repeat the same for grouping by Gender in bank data and calculating median Salary\n",
    "\n",
    "#e.g., \n",
    "bank_1['Salary'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#. Repeat the same for grouping by PCJob in bank data and calculating median Salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# complex filtering\n",
    "# what does this function do?\n",
    "bank[(bank['Gender'] == 'Female') & (bank['JobGrade'] == 1)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise:\n",
    "# what does this function do?>\n",
    "mgmt = [4,5,6]\n",
    "bank[bank['JobGrade'].isin(mgmt)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recoding Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appending or adding columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's add a new column called “Dummy” and set every value in the series to zero.\n",
    "bank['Dummy'] = 0\n",
    "bank.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's drop this column! coz it's useless\n",
    "Like many functions in Pandas, drop requires an axis argument (where 0=row and 1=column). \n",
    "The inplace = True argument is also common in Pandas: it is equivalent to bank = bank.drop(...). \n",
    "That is, it ensures the changes are not part of a new data frame but are written back to the original data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank.drop('Dummy', axis=1, inplace=True)\n",
    "bank.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
